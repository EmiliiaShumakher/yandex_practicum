{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Содержание<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Подготовка\" data-toc-modified-id=\"Подготовка-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Подготовка</a></span><ul class=\"toc-item\"><li><span><a href=\"#Обзор-данных\" data-toc-modified-id=\"Обзор-данных-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Обзор данных</a></span></li><li><span><a href=\"#Обработка-данных\" data-toc-modified-id=\"Обработка-данных-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Обработка данных</a></span><ul class=\"toc-item\"><li><span><a href=\"#Очистка-текста\" data-toc-modified-id=\"Очистка-текста-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Очистка текста</a></span></li><li><span><a href=\"#Лемматизация\" data-toc-modified-id=\"Лемматизация-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Лемматизация</a></span></li><li><span><a href=\"#Разделение-на-выборки\" data-toc-modified-id=\"Разделение-на-выборки-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Разделение на выборки</a></span></li></ul></li><li><span><a href=\"#Векторизация\" data-toc-modified-id=\"Векторизация-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Векторизация</a></span></li></ul></li><li><span><a href=\"#Обучение\" data-toc-modified-id=\"Обучение-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Обучение</a></span><ul class=\"toc-item\"><li><span><a href=\"#LogisticRegression\" data-toc-modified-id=\"LogisticRegression-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>LogisticRegression</a></span></li><li><span><a href=\"#RandomForest\" data-toc-modified-id=\"RandomForest-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>RandomForest</a></span></li><li><span><a href=\"#Catboost\" data-toc-modified-id=\"Catboost-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Catboost</a></span></li></ul></li><li><span><a href=\"#Тестирование\" data-toc-modified-id=\"Тестирование-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Тестирование</a></span></li><li><span><a href=\"#Выводы\" data-toc-modified-id=\"Выводы-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Выводы</a></span></li><li><span><a href=\"#Чек-лист-проверки\" data-toc-modified-id=\"Чек-лист-проверки-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Чек-лист проверки</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проект для «Викишоп»"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества *F1* не меньше 0.75. \n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели. \n",
    "3. Сделайте выводы.\n",
    "\n",
    "Для выполнения проекта применять *BERT* необязательно, но вы можете попробовать.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pattern in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (3.6)\n",
      "Requirement already satisfied: future in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (0.18.3)\n",
      "Requirement already satisfied: backports.csv in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (1.0.7)\n",
      "Requirement already satisfied: mysqlclient in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (2.2.0)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (4.9.3)\n",
      "Requirement already satisfied: lxml in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (4.9.3)\n",
      "Requirement already satisfied: feedparser in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (6.0.10)\n",
      "Requirement already satisfied: pdfminer.six in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (20221105)\n",
      "Requirement already satisfied: numpy in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (1.20.1)\n",
      "Requirement already satisfied: scipy in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (1.8.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (3.6.1)\n",
      "Requirement already satisfied: python-docx in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (0.8.11)\n",
      "Requirement already satisfied: cherrypy in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (18.8.0)\n",
      "Requirement already satisfied: requests in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pattern) (2.29.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from beautifulsoup4->pattern) (2.3.2.post1)\n",
      "Requirement already satisfied: cheroot>=8.2.1 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from cherrypy->pattern) (10.0.0)\n",
      "Requirement already satisfied: portend>=2.1.1 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from cherrypy->pattern) (3.2.0)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from cherrypy->pattern) (9.1.0)\n",
      "Requirement already satisfied: zc.lockfile in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from cherrypy->pattern) (3.0.post1)\n",
      "Requirement already satisfied: jaraco.collections in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from cherrypy->pattern) (4.3.0)\n",
      "Requirement already satisfied: pywin32>=227 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from cherrypy->pattern) (304)\n",
      "Requirement already satisfied: sgmllib3k in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from feedparser->pattern) (1.0.0)\n",
      "Requirement already satisfied: click in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from nltk->pattern) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from nltk->pattern) (1.2.0)\n",
      "Requirement already satisfied: regex in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from nltk->pattern) (2022.3.15)\n",
      "Requirement already satisfied: tqdm in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from nltk->pattern) (4.65.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pdfminer.six->pattern) (3.1.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pdfminer.six->pattern) (40.0.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->pattern) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->pattern) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from requests->pattern) (2022.12.7)\n",
      "Requirement already satisfied: jaraco.functools in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from cheroot>=8.2.1->cherrypy->pattern) (3.8.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six->pattern) (1.15.1)\n",
      "Requirement already satisfied: tempora>=1.8 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from portend>=2.1.1->cherrypy->pattern) (5.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from click->nltk->pattern) (0.4.6)\n",
      "Requirement already satisfied: jaraco.text in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from jaraco.collections->cherrypy->pattern) (3.11.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from zc.lockfile->cherrypy->pattern) (67.7.2)\n",
      "Requirement already satisfied: pycparser in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six->pattern) (2.21)\n",
      "Requirement already satisfied: pytz in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from tempora>=1.8->portend>=2.1.1->cherrypy->pattern) (2023.3)\n",
      "Requirement already satisfied: jaraco.context>=4.1 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (4.3.0)\n",
      "Requirement already satisfied: autocommand in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (2.2.2)\n",
      "Requirement already satisfied: inflect in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from jaraco.text->jaraco.collections->cherrypy->pattern) (7.0.0)\n",
      "Requirement already satisfied: pydantic>=1.9.1 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (2.0.2)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (4.7.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pydantic>=1.9.1->inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (0.5.0)\n",
      "Requirement already satisfied: pydantic-core==2.1.2 in c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages (from pydantic>=1.9.1->inflect->jaraco.text->jaraco.collections->cherrypy->pattern) (2.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import pattern\n",
    "from pattern.en import lemma\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "random_state = 12345"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обзор данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    data = pd.read_csv('datasets\\\\toxic_comments.csv', index_col=[0])\n",
    "except:\n",
    "    data = pd.read_csv('https://code.s3.yandex.net/datasets/toxic_comments.csv', index_col=[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тексты на английском языке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 159292 entries, 0 to 159450\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159292 non-null  object\n",
      " 1   toxic   159292 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пропусков нет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.9\n",
       "1    0.1\n",
       "Name: toxic, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data.toxic.value_counts() / data.shape[0]).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень сильный дисбаланс классов, это нужно будет учесть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дубликатов нет"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Очистка текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  d aww he matches this background colour i m se...      0\n",
       "2  hey man i m really not trying to edit war it s...      0\n",
       "3  more i can t make any real suggestions on impr...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# приводим весь текст к нижнему регистру\n",
    "data['text'] = data['text'].str.lower()\n",
    "# заменяем символ переноса строки на пробел\n",
    "data['text'] = data['text'].str.replace('\\n',' ')\n",
    "# удаляем лишние символы\n",
    "data['text'] = data['text'].apply((lambda x: re.sub(\"[^a-z0-9\\s]\",' ',x)))\n",
    "#удаляем лишние пробелы\n",
    "data['text'] = data['text'].apply((lambda x: \" \".join(x.split())))\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь отфильтруем текст от стоп-слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>0</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  explanation why the edits made under my userna...      0   \n",
       "1  d aww he matches this background colour i m se...      0   \n",
       "2  hey man i m really not trying to edit war it s...      0   \n",
       "3  more i can t make any real suggestions on impr...      0   \n",
       "4  you sir are my hero any chance you remember wh...      0   \n",
       "\n",
       "                                       filtered_text  \n",
       "0  explanation edits made username hardcore metal...  \n",
       "1  aww matches background colour seemingly stuck ...  \n",
       "2  hey man really trying edit war guy constantly ...  \n",
       "3  make real suggestions improvement wondered sec...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_en = stopwords.words('english')\n",
    "data['filtered_text'] = data['text'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stopwords_en)]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Лемматизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    print(lemma(\"I don't like exceptions\"))\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d aww he matches this background colour i m se...</td>\n",
       "      <td>0</td>\n",
       "      <td>aww match background colour seemingly stick th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>0</td>\n",
       "      <td>hey man really try edit war guy constantly rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>more i can t make any real suggestions on impr...</td>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestion improvement wonder sectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic  \\\n",
       "0  explanation why the edits made under my userna...      0   \n",
       "1  d aww he matches this background colour i m se...      0   \n",
       "2  hey man i m really not trying to edit war it s...      0   \n",
       "3  more i can t make any real suggestions on impr...      0   \n",
       "4  you sir are my hero any chance you remember wh...      0   \n",
       "\n",
       "                                       filtered_text  \n",
       "0  explanation edit make username hardcore metall...  \n",
       "1  aww match background colour seemingly stick th...  \n",
       "2  hey man really try edit war guy constantly rem...  \n",
       "3  make real suggestion improvement wonder sectio...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['filtered_text'] = data['filtered_text'].apply(lambda x: \" \".join([lemma(wd) for wd in x.split()]))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Разделение на выборки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделение на выборки проводим перед векторизацией."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(data, test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Валидационные данные пока отделять не будем. А тестовые данные отложим до финального тестирования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus = train['filtered_text'].values\n",
    "count_tf_idf = TfidfVectorizer()\n",
    "count_tf_idf.fit(corpus) \n",
    "tf_idf = count_tf_idf.transform(corpus)\n",
    "tfidf_tokens = count_tf_idf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "136800"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tfidf_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такое количество слов мы не можем обработать.  \n",
    "Выделим словрь из 8000 самых популярных слов и отфильтруем данные по нему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "N = 8000\n",
    "# индексы топ N столбцов с максимальной суммой элементов (в столбцах)\n",
    "idx = np.ravel(tf_idf.sum(axis=0).argsort(axis=1))[::-1][:N]\n",
    "top_N_words = np.array(count_tf_idf.get_feature_names())[idx].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergey_qt\\AppData\\Local\\Temp\\ipykernel_1604\\3512392500.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  train['filtered_text'] = train['filtered_text'].apply(lambda x: ' '.join([word for word in x.split() if word in (top_N_words)]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>97494</th>\n",
       "      <td>bushranger you re a grass with no sense of hum...</td>\n",
       "      <td>1</td>\n",
       "      <td>grass sense humour see south park episode poor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4383</th>\n",
       "      <td>need administrative help i have been blocked i...</td>\n",
       "      <td>0</td>\n",
       "      <td>need administrative help block read request tr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103777</th>\n",
       "      <td>i d also like to point out that he has used a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>also like point used third person plural prono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38619</th>\n",
       "      <td>you cant block me you fucking retard brb nigger</td>\n",
       "      <td>1</td>\n",
       "      <td>cant block fuck retard nigger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128443</th>\n",
       "      <td>i believe that the frequency of the wave needs...</td>\n",
       "      <td>0</td>\n",
       "      <td>believe frequency wave need change 15 duration...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "97494   bushranger you re a grass with no sense of hum...      1   \n",
       "4383    need administrative help i have been blocked i...      0   \n",
       "103777  i d also like to point out that he has used a ...      0   \n",
       "38619     you cant block me you fucking retard brb nigger      1   \n",
       "128443  i believe that the frequency of the wave needs...      0   \n",
       "\n",
       "                                            filtered_text  \n",
       "97494   grass sense humour see south park episode poor...  \n",
       "4383    need administrative help block read request tr...  \n",
       "103777  also like point used third person plural prono...  \n",
       "38619                       cant block fuck retard nigger  \n",
       "128443  believe frequency wave need change 15 duration...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['filtered_text'] = train['filtered_text'].apply(lambda x: ' '.join([word for word in x.split() if word in (top_N_words)]))\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь ещё раз проведём векторизацию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000000</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>04</th>\n",
       "      <th>05</th>\n",
       "      <th>06</th>\n",
       "      <th>07</th>\n",
       "      <th>...</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeu</th>\n",
       "      <th>zionism</th>\n",
       "      <th>zionist</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zora</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 8000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    00  000  000000   01   02   03   04   05   06   07  ...  zealand  zero  \\\n",
       "0  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0   \n",
       "1  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0   \n",
       "2  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0   \n",
       "3  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0   \n",
       "4  0.0  0.0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...      0.0   0.0   \n",
       "\n",
       "   zeu  zionism  zionist  zoe  zombie  zone  zoo  zora  \n",
       "0  0.0      0.0      0.0  0.0     0.0   0.0  0.0   0.0  \n",
       "1  0.0      0.0      0.0  0.0     0.0   0.0  0.0   0.0  \n",
       "2  0.0      0.0      0.0  0.0     0.0   0.0  0.0   0.0  \n",
       "3  0.0      0.0      0.0  0.0     0.0   0.0  0.0   0.0  \n",
       "4  0.0      0.0      0.0  0.0     0.0   0.0  0.0   0.0  \n",
       "\n",
       "[5 rows x 8000 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = train['filtered_text'].values\n",
    "count_tf_idf = TfidfVectorizer()\n",
    "count_tf_idf.fit(corpus) \n",
    "\n",
    "tf_idf = count_tf_idf.transform(corpus)\n",
    "tfidf_tokens = count_tf_idf.get_feature_names()\n",
    "\n",
    "df_tfidfvect = pd.DataFrame(data = tf_idf.toarray(),columns = tfidf_tokens)\n",
    "df_tfidfvect.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(df_tfidfvect, train['toxic'], test_size=0.2, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для устранения дисбаланса здесь и далее будем использовать взвешенные классы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sergey_qt\\anaconda3\\envs\\practicum\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 31min 14s\n",
      "Wall time: 5min 33s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_linear_model = None\n",
    "best_iter = 0\n",
    "best_linear_f1 = 0\n",
    "for iter in range(100, 201, 50):\n",
    "    linear_model = LogisticRegression(class_weight='balanced', max_iter=iter, random_state=random_state)\n",
    "    linear_model.fit(x_train, y_train)\n",
    "    linear_prediction = (linear_model.predict(x_valid))\n",
    "    f1_score_linear = f1_score(y_valid, linear_prediction)\n",
    "    if f1_score_linear > best_linear_f1:\n",
    "        best_linear_model = linear_model\n",
    "        best_iter = iter\n",
    "        best_linear_f1 = f1_score_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7199341021416804, 100)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_linear_f1, best_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший порог: 0.76 \n",
      "F1: 0.7696768848384425\n"
     ]
    }
   ],
   "source": [
    "probabilities_weighted = best_linear_model.predict_proba(x_valid)[:, 1]\n",
    "\n",
    "best_linear_f1_threshold = 0\n",
    "best_threshold = 0\n",
    "for threshold in np.arange(0, 1, 0.01):\n",
    "    predicted_valid = probabilities_weighted > threshold\n",
    "    score = f1_score(y_valid, predicted_valid)\n",
    "    if best_linear_f1_threshold < score:\n",
    "        best_linear_f1_threshold = score\n",
    "        best_linear_threshold = threshold\n",
    "print('Лучший порог:',best_linear_threshold,'\\nF1:', best_linear_f1_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 2h 28min 24s\n",
      "Wall time: 2h 28min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_forest_model = None\n",
    "best_est = 0\n",
    "best_forest_f1 = 0\n",
    "for est in range(100, 501, 200):\n",
    "    forest_model = RandomForestClassifier(n_estimators=est, class_weight='balanced', random_state=random_state)\n",
    "    forest_model.fit(x_train, y_train)\n",
    "    forest_prediction = forest_model.predict(x_valid)\n",
    "    f1_score_forest = f1_score(y_valid, forest_prediction)\n",
    "    if f1_score_forest > best_forest_f1:\n",
    "        best_forest_model = forest_model\n",
    "        best_est = est\n",
    "        best_forest_f1 = f1_score_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.6988610478359908, 300)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_forest_f1, best_est"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший порог: 0.33 \n",
      "F1: 0.7352425482174166\n"
     ]
    }
   ],
   "source": [
    "probabilities_weighted = best_forest_model.predict_proba(x_valid)[:, 1]\n",
    "\n",
    "best_forest_f1_threshold = 0\n",
    "best_forest_threshold = 0\n",
    "for threshold in np.arange(0, 1, 0.01):\n",
    "    predicted_valid = probabilities_weighted > threshold\n",
    "    score = f1_score(y_valid, predicted_valid)\n",
    "    if best_forest_f1_threshold < score:\n",
    "        best_forest_f1_threshold = score\n",
    "        best_forest_threshold = threshold\n",
    "print('Лучший порог:',best_forest_threshold,'\\nF1:', best_forest_f1_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "classes = np.unique(y_train)\n",
    "weights = compute_class_weight(class_weight='balanced', classes=classes, y=y_train)\n",
    "class_weights = dict(zip(classes, weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Custom logger is already specified. Specify more than one logger at same time is not thread safe."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.140137\n",
      "0:\tlearn: 0.6288894\ttotal: 1.5s\tremaining: 12m 27s\n",
      "499:\tlearn: 0.1916455\ttotal: 3m 47s\tremaining: 0us\n",
      "Learning rate set to 0.074218\n",
      "0:\tlearn: 0.6558981\ttotal: 954ms\tremaining: 15m 53s\n",
      "500:\tlearn: 0.2433495\ttotal: 3m 35s\tremaining: 3m 34s\n",
      "999:\tlearn: 0.1877493\ttotal: 7m 6s\tremaining: 0us\n",
      "Learning rate set to 0.051172\n",
      "0:\tlearn: 0.6666568\ttotal: 1.25s\tremaining: 31m 12s\n",
      "500:\tlearn: 0.2730325\ttotal: 3m 36s\tremaining: 7m 12s\n",
      "1000:\tlearn: 0.2170115\ttotal: 7m 5s\tremaining: 3m 32s\n",
      "1499:\tlearn: 0.1847010\ttotal: 10m 34s\tremaining: 0us\n",
      "CPU times: total: 2h 39min 39s\n",
      "Wall time: 24min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "best_cat_model = None\n",
    "best_iter = 0\n",
    "best_cat_f1 = 0\n",
    "for iterations in range(500, 1501, 500):\n",
    "    cat_model = CatBoostClassifier(iterations=iterations,class_weights=class_weights,random_seed=random_state)\n",
    "    cat_model.fit(x_train, y_train, verbose=500)\n",
    "    cat_prediction = cat_model.predict(x_valid)\n",
    "    f1_score_cat = f1_score(y_valid, cat_prediction)\n",
    "    if f1_score_cat > best_cat_f1:\n",
    "        best_cat_model = cat_model\n",
    "        best_iter = iterations\n",
    "        best_cat_f1 = f1_score_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7536646406864498, 1500)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_cat_f1, best_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший порог: 0.67 \n",
      "F1: 0.776321179844326\n"
     ]
    }
   ],
   "source": [
    "probabilities_weighted = best_cat_model.predict_proba(x_valid)[:, 1]\n",
    "\n",
    "best_cat_f1_threshold = 0\n",
    "best_cat_threshold = 0\n",
    "for threshold in np.arange(0, 1, 0.01):\n",
    "    predicted_valid = probabilities_weighted > threshold\n",
    "    score = f1_score(y_valid, predicted_valid)\n",
    "    if best_cat_f1_threshold < score:\n",
    "        best_cat_f1_threshold = score\n",
    "        best_cat_threshold = threshold\n",
    "print('Лучший порог:',best_cat_threshold,'\\nF1:', best_cat_f1_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression F1: 0.7696768848384425\n",
      "RandomForest F1: 0.7352425482174166\n",
      "CatBoost F1: 0.776321179844326\n"
     ]
    }
   ],
   "source": [
    "print('LogisticRegression F1:', best_linear_f1_threshold)\n",
    "print('RandomForest F1:', best_forest_f1_threshold)\n",
    "print('CatBoost F1:', best_cat_f1_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С небольшим перевесом победил CatBoost. Обучим его заново на объединении тренировочных и валидационных данных для лучшего результата. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_model = cat_model\n",
    "best_threshold = best_cat_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.056288\n",
      "0:\tlearn: 0.6629656\ttotal: 1.68s\tremaining: 41m 58s\n",
      "100:\tlearn: 0.3905029\ttotal: 50.9s\tremaining: 11m 45s\n",
      "200:\tlearn: 0.3424325\ttotal: 1m 38s\tremaining: 10m 39s\n",
      "300:\tlearn: 0.3093738\ttotal: 2m 26s\tremaining: 9m 44s\n",
      "400:\tlearn: 0.2868954\ttotal: 3m 14s\tremaining: 8m 52s\n",
      "500:\tlearn: 0.2694899\ttotal: 4m 1s\tremaining: 8m 2s\n",
      "600:\tlearn: 0.2551498\ttotal: 4m 49s\tremaining: 7m 13s\n",
      "700:\tlearn: 0.2436057\ttotal: 5m 37s\tremaining: 6m 24s\n",
      "800:\tlearn: 0.2331731\ttotal: 6m 25s\tremaining: 5m 36s\n",
      "900:\tlearn: 0.2244824\ttotal: 7m 12s\tremaining: 4m 47s\n",
      "1000:\tlearn: 0.2166047\ttotal: 8m\tremaining: 3m 59s\n",
      "1100:\tlearn: 0.2092886\ttotal: 8m 47s\tremaining: 3m 11s\n",
      "1200:\tlearn: 0.2027350\ttotal: 9m 35s\tremaining: 2m 23s\n",
      "1300:\tlearn: 0.1966544\ttotal: 10m 23s\tremaining: 1m 35s\n",
      "1400:\tlearn: 0.1912660\ttotal: 11m 10s\tremaining: 47.4s\n",
      "1499:\tlearn: 0.1858623\ttotal: 11m 57s\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1619b459580>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model.fit(df_tfidfvect, train['toxic'], verbose=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем тестовые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "corpus_test = test['filtered_text'].values\n",
    "\n",
    "tf_idf_test = count_tf_idf.transform(corpus_test)\n",
    "\n",
    "df_tfidfvect_test = pd.DataFrame(data = tf_idf_test.toarray(),columns = tfidf_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Проверяем модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7898457583547558"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test = df_tfidfvect_test\n",
    "y_test = test['toxic']\n",
    "\n",
    "probabilities_test = best_model.predict_proba(x_test)[:, 1]\n",
    "predicted_test = probabilities_test > best_threshold\n",
    "test_score = f1_score(y_test, predicted_test)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбранный вариант векторизации слов очень простой - он не учитывает порядок слов или их близость по смыслу. Однако нам удалось достигнуть поставленного порога метрики F1 в 0.75.  \n",
    "Лучший результат показала следующая модель:  \n",
    "**CatBoost**\n",
    "* F1 = 0.79\n",
    "* iterations = 1500"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Содержание",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "302.391px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
